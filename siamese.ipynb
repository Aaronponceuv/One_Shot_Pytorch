{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import walk\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = './images_background/'\n",
    "categories = [[folder, os.listdir(root_dir + folder)] for folder in os.listdir(root_dir)  if not folder.startswith('.') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OmniglotDataset(Dataset):\n",
    "    def __init__(self, categories, root_dir, setSize, transform=None):\n",
    "        self.categories = categories\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.setSize = setSize\n",
    "    def __len__(self):\n",
    "        return self.setSize\n",
    "    def __getitem__(self, idx):\n",
    "        img1 = None\n",
    "        img2 = None\n",
    "        label = None\n",
    "        if idx % 2 == 0: # select the same character for both images\n",
    "            category = random.choice(categories)\n",
    "            character = random.choice(category[1])\n",
    "            imgDir = root_dir + category[0] + '/' + character\n",
    "            img1Name = random.choice(os.listdir(imgDir))\n",
    "            img2Name = random.choice(os.listdir(imgDir))\n",
    "            img1 = Image.open(imgDir + '/' + img1Name)\n",
    "            img2 = Image.open(imgDir + '/' + img2Name)\n",
    "            label = 1.0\n",
    "        else: # select a different character for both images\n",
    "            category1, category2 = random.choice(categories), random.choice(categories)\n",
    "            category1, category2 = random.choice(categories), random.choice(categories)\n",
    "            character1, character2 = random.choice(category1[1]), random.choice(category2[1])\n",
    "            imgDir1, imgDir2 = root_dir + category1[0] + '/' + character1, root_dir + category2[0] + '/' + character2\n",
    "            img1Name = random.choice(os.listdir(imgDir1))\n",
    "            img2Name = random.choice(os.listdir(imgDir2))\n",
    "            while img1Name == img2Name:\n",
    "                img2Name = random.choice(os.listdir(imgDir2))\n",
    "            label = 0.0\n",
    "            img1 = Image.open(imgDir1 + '/' + img1Name)\n",
    "            img2 = Image.open(imgDir2 + '/' + img2Name)\n",
    "#         plt.imshow(img1)\n",
    "        if self.transform:\n",
    "            img1 = self.transform(img1)\n",
    "            img2 = self.transform(img2)\n",
    "        return img1, img2, torch.from_numpy(np.array([label], dtype=np.float32))          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSize = 6000 # self-defined dataset size\n",
    "TRAIN_PCT = 0.8 # percentage of entire dataset for training\n",
    "train_size = int(dataSize * TRAIN_PCT)\n",
    "val_size = dataSize - train_size\n",
    "\n",
    "IMG_SIZE = 32\n",
    "transformations = transforms.Compose(\n",
    "    [transforms.ToTensor()]) \n",
    "\n",
    "omniglotDataset = OmniglotDataset(categories, root_dir, 6000, transformations)\n",
    "train_set, val_set = random_split(omniglotDataset, [train_size, val_size])\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=4, num_workers=0)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=1, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 105, 105])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for img1, img2, label in train_loader:\n",
    "    print(img1.shape)\n",
    "    plt.imshow(img1[0][0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # Conv2d(input_channels, output_channels, kernel_size)\n",
    "        self.conv1 = nn.Conv2d(1, 64, 10) \n",
    "        self.conv2 = nn.Conv2d(64, 128, 7)  \n",
    "        self.conv3 = nn.Conv2d(128, 128, 4)\n",
    "        self.conv4 = nn.Conv2d(128, 256, 4)\n",
    "        self.fc1 = nn.Linear(256 * 6 * 6, 4096)\n",
    "        self.fcOut = nn.Linear(4096, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def convs(self, x):\n",
    "\n",
    "        # out_dim = in_dim - kernel_size + 1  \n",
    "        #1, 105, 105\n",
    "        x = F.relu(self.conv1(x))\n",
    "        # 64, 96, 96\n",
    "        x = F.max_pool2d(x, (2,2))\n",
    "        # 64, 48, 48\n",
    "        x = F.relu(self.conv2(x))\n",
    "        # 128, 42, 42\n",
    "        x = F.max_pool2d(x, (2,2))\n",
    "        # 128, 21, 21\n",
    "        x = F.relu(self.conv3(x))\n",
    "        # 128, 18, 18\n",
    "        x = F.max_pool2d(x, (2,2))\n",
    "        # 128, 9, 9\n",
    "        x = F.relu(self.conv4(x))\n",
    "        # 256, 6, 6\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.convs(x1)\n",
    "        x1 = x1.view(-1, 256 * 6 * 6)\n",
    "        x1 = self.sigmoid(self.fc1(x1))\n",
    "        x2 = self.convs(x2)\n",
    "        x2 = x2.view(-1, 256 * 6 * 6)\n",
    "        x2 = self.sigmoid(self.fc1(x2))\n",
    "        x = torch.abs(x1 - x2)\n",
    "        x = self.sigmoid(self.fcOut(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "siameseBaseLine = Net()\n",
    "siameseBaseLine = siameseBaseLine.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(save_path, model, optimizer, val_loss):\n",
    "    if save_path==None:\n",
    "        return\n",
    "    save_path = save_path \n",
    "    state_dict = {'model_state_dict': model.state_dict(),\n",
    "                  'optimizer_state_dict': optimizer.state_dict(),\n",
    "                  'val_loss': val_loss}\n",
    "\n",
    "    torch.save(state_dict, save_path)\n",
    "\n",
    "    print(f'Model saved to ==> {save_path}')\n",
    "\n",
    "def load_checkpoint(model, optimizer):\n",
    "    save_path = f'siameseNet.pt'\n",
    "    state_dict = torch.load(save_path)\n",
    "    model.load_state_dict(state_dict['model_state_dict'])\n",
    "    optimizer.load_state_dict(state_dict['optimizer_state_dict'])\n",
    "    val_loss = state_dict['val_loss']\n",
    "    print(f'Model loaded from <== {save_path}')\n",
    "    \n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, num_epochs, criterion, save_name):\n",
    "    best_val_loss = float(\"Inf\") \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for img1, img2, labels in train_loader:\n",
    "            model.train()\n",
    "            \n",
    "            # Forward\n",
    "            img1 = img1.to(device)\n",
    "            img2 = img2.to(device)\n",
    "            outputs = model(img1, img2)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        val_running_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for img1, img2, labels in val_loader:\n",
    "                img1 = img1.to(device)\n",
    "                img2 = img2.to(device)\n",
    "                outputs = net(img1, img2)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_running_loss += loss.item()\n",
    "        avg_val_loss = val_running_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        print('Epoch [{}/{}],Train Loss: {:.4f}, Valid Loss: {:.4f}'\n",
    "            .format(epoch+1, num_epochs, avg_train_loss, avg_val_loss))\n",
    "        if average_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            save_checkpoint(save_name, net, optimizer, best_val_loss)\n",
    "    \n",
    "    print(\"Finished Training\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(siameseBaseLine.parameters(), lr = 0.001)\n",
    "num_epochs = 10\n",
    "criterion = nn.BCELoss()\n",
    "save_path = 'siameseNet.pt'\n",
    "train_losses, val_losses = train(siameseBaseLine, train_loader, val_loader, num_epochs, criterion, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
