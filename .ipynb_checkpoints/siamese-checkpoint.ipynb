{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import walk\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = './images_background/'\n",
    "categories = [[folder, os.listdir(root_dir + folder)] for folder in os.listdir(root_dir)  if not folder.startswith('.') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OmniglotDataset(Dataset):\n",
    "    def __init__(self, categories, root_dir, setSize, transform=None):\n",
    "        self.categories = categories\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.setSize = setSize\n",
    "    def __len__(self):\n",
    "        return self.setSize\n",
    "    def __getitem__(self, idx):\n",
    "        img1 = None\n",
    "        img2 = None\n",
    "        label = None\n",
    "        if idx % 2 == 0: # select the same character for both images\n",
    "            category = random.choice(categories)\n",
    "            character = random.choice(category[1])\n",
    "            imgDir = root_dir + category[0] + '/' + character\n",
    "            img1Name = random.choice(os.listdir(imgDir))\n",
    "            img2Name = random.choice(os.listdir(imgDir))\n",
    "            img1 = Image.open(imgDir + '/' + img1Name)\n",
    "            img2 = Image.open(imgDir + '/' + img2Name)\n",
    "            label = 1.0\n",
    "        else: # select a different character for both images\n",
    "            category1, category2 = random.choice(categories), random.choice(categories)\n",
    "            category1, category2 = random.choice(categories), random.choice(categories)\n",
    "            character1, character2 = random.choice(category1[1]), random.choice(category2[1])\n",
    "            imgDir1, imgDir2 = root_dir + category1[0] + '/' + character1, root_dir + category2[0] + '/' + character2\n",
    "            img1Name = random.choice(os.listdir(imgDir1))\n",
    "            img2Name = random.choice(os.listdir(imgDir2))\n",
    "            while img1Name == img2Name:\n",
    "                img2Name = random.choice(os.listdir(imgDir2))\n",
    "            label = 0.0\n",
    "            img1 = Image.open(imgDir1 + '/' + img1Name)\n",
    "            img2 = Image.open(imgDir2 + '/' + img2Name)\n",
    "#         plt.imshow(img1)\n",
    "        if self.transform:\n",
    "            img1 = self.transform(img1)\n",
    "            img2 = self.transform(img2)\n",
    "        print(img1)\n",
    "        return img1, img2, torch.from_numpy(np.array([label], dtype=np.float32))          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSize = 6000 # self-defined dataset size\n",
    "TRAIN_PCT = 0.8 # percentage of entire dataset for training\n",
    "train_size = int(dataSize * TRAIN_PCT)\n",
    "val_size = dataSize - train_size\n",
    "\n",
    "IMG_SIZE = 32\n",
    "transformations = transforms.Compose(\n",
    "    [transforms.ToTensor()]) \n",
    "\n",
    "omniglotDataset = OmniglotDataset(categories, root_dir, 6000, transformations)\n",
    "train_set, val_set = random_split(omniglotDataset, [train_size, val_size])\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=4, num_workers=0)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=1, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 105, 105])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for img1, img2, label in train_loader:\n",
    "    print(img1.shape)\n",
    "    plt.imshow(img1[0][0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # Conv2d(input_channels, output_channels, kernel_size)\n",
    "        self.conv1 = nn.Conv2d(1, 64, 10) \n",
    "        self.conv2 = nn.Conv2d(64, 128, 7)  \n",
    "        self.conv3 = nn.Conv2d(128, 128, 4)\n",
    "        self.conv4 = nn.Conv2d(128, 256, 4)\n",
    "        self.fc1 = nn.Linear(256 * 6 * 6, 4096)\n",
    "        self.fcOut = nn.Linear(4096, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def convs(self, x):\n",
    "\n",
    "        # out_dim = in_dim - kernel_size + 1  \n",
    "        \n",
    "        #1, 105, 105\n",
    "        x = F.relu(self.conv1(x))\n",
    "        # 64, 96, 96\n",
    "        x = F.max_pool2d(x, (2,2))\n",
    "        # 64, 48, 48\n",
    "        x = F.relu(self.conv2(x))\n",
    "        # 128, 42, 42\n",
    "        x = F.max_pool2d(x, (2,2))\n",
    "        # 128, 21, 21\n",
    "        x = F.relu(self.conv3(x))\n",
    "        # 128, 18, 18\n",
    "        x = F.max_poolwd(x, (2,2))\n",
    "        # 128, 9, 9\n",
    "        x = F.relu(self.conv4(x))\n",
    "        # 256, 6, 6\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.convs(x1)\n",
    "        x1 = x1.view(-1, 256 * 6 * 6)\n",
    "        x1 = self.sigmoid(self.fc1(x1))\n",
    "        x2 = self.convs(x2)\n",
    "        x2 = x2.view(-1, 256 * 6 * 6)\n",
    "        x = torch.abs(x1 - x2)\n",
    "        x = self.fcOut(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "siameseBaseLine = Net()\n",
    "siameseBaseLine = siameseBaseLine.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
